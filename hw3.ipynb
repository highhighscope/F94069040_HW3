{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW3 - Stock Movement Prediction\n",
    "\n",
    "作業檔案：\n",
    "- hw3.ipynb\n",
    "\n",
    "資料：\n",
    "https://www.sharecast.com/index/SP_500/prices/download\n",
    "\n",
    "- train.csv: S&P 500 訓練資料(2009-2017)\n",
    "- test.csv: S&P 500 測試資料(2018)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2264, 6)\n",
      "          Date  Open Price  Close Price  High Price  Low Price      Volume\n",
      "0  02-Jan-2009      902.99       931.80      934.73     899.35  4048270080\n",
      "1  05-Jan-2009      929.17       927.45      936.63     919.53  5413910016\n",
      "2  06-Jan-2009      931.17       934.70      943.85     927.28  5392620032\n",
      "3  07-Jan-2009      927.45       906.65      927.45     902.37  4704940032\n",
      "4  08-Jan-2009      905.73       909.73      910.00     896.81  4991549952\n",
      "(252, 6)\n",
      "          Date  Open Price  Close Price  High Price  Low Price      Volume\n",
      "0  02-Jan-2018     2683.73      2695.81     2695.89    2682.36  1846463232\n",
      "1  03-Jan-2018     2697.85      2713.06     2714.37    2697.77  2090595328\n",
      "2  04-Jan-2018     2719.31      2723.99     2729.29    2719.07  2100767744\n",
      "3  05-Jan-2018     2731.33      2743.15     2743.45    2727.92  1918869120\n",
      "4  08-Jan-2018     2742.67      2747.71     2748.51    2737.60  1894823936\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_data_path = './train.csv'\n",
    "test_data_path = './test.csv'\n",
    "\n",
    "train_df = pd.read_csv(train_data_path)\n",
    "test_df = pd.read_csv(test_data_path)\n",
    "\n",
    "print(train_df.shape)\n",
    "print(train_df.head())\n",
    "print(test_df.shape)\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2264, 5)\n",
      "   Open Price  Close Price  High Price  Low Price      Volume\n",
      "0      902.99       931.80      934.73     899.35  4048270080\n",
      "1      929.17       927.45      936.63     919.53  5413910016\n",
      "2      931.17       934.70      943.85     927.28  5392620032\n",
      "3      927.45       906.65      927.45     902.37  4704940032\n",
      "4      905.73       909.73      910.00     896.81  4991549952\n",
      "(252, 5)\n",
      "   Open Price  Close Price  High Price  Low Price      Volume\n",
      "0     2683.73      2695.81     2695.89    2682.36  1846463232\n",
      "1     2697.85      2713.06     2714.37    2697.77  2090595328\n",
      "2     2719.31      2723.99     2729.29    2719.07  2100767744\n",
      "3     2731.33      2743.15     2743.45    2727.92  1918869120\n",
      "4     2742.67      2747.71     2748.51    2737.60  1894823936\n"
     ]
    }
   ],
   "source": [
    "# Drop unnecessary columns\n",
    "\n",
    "drop_col_names = ['Date'] # !--- or you can modify it to drop the columns you don't want ---!\n",
    "\n",
    "train_df.drop(columns=drop_col_names, inplace=True)\n",
    "test_df.drop(columns=drop_col_names, inplace=True)\n",
    "\n",
    "print(train_df.shape)\n",
    "print(train_df.head())\n",
    "print(test_df.shape)\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Open Price  Close Price  High Price  Low Price      Volume  \\\n",
      "0      902.99       931.80      934.73     899.35  4048270080   \n",
      "1      929.17       927.45      936.63     919.53  5413910016   \n",
      "2      931.17       934.70      943.85     927.28  5392620032   \n",
      "3      927.45       906.65      927.45     902.37  4704940032   \n",
      "4      905.73       909.73      910.00     896.81  4991549952   \n",
      "\n",
      "   Tomorrow Movement  \n",
      "0                0.0  \n",
      "1                1.0  \n",
      "2                0.0  \n",
      "3                1.0  \n",
      "4                0.0  \n",
      "      Open Price  Close Price  High Price  Low Price      Volume  \\\n",
      "2259     2684.22      2683.34     2685.35    2678.13  1383888512   \n",
      "2260     2679.09      2680.50     2682.74    2677.96  1103808384   \n",
      "2261     2682.10      2682.62     2685.64    2678.91  1149108352   \n",
      "2262     2686.10      2687.54     2687.66    2682.69  1126089856   \n",
      "2263     2689.15      2673.61     2692.12    2673.61  1332374016   \n",
      "\n",
      "      Tomorrow Movement  \n",
      "2259                0.0  \n",
      "2260                1.0  \n",
      "2261                1.0  \n",
      "2262                0.0  \n",
      "2263                NaN  \n"
     ]
    }
   ],
   "source": [
    "# Add the column `Tomorrow Movement` by comparing the `Close Price` with the previous days as the training target\n",
    "\n",
    "train_df['Tomorrow Movement'] = np.where(train_df['Close Price'].diff() >= 0, 1, 0)\n",
    "test_df['Tomorrow Movement'] = np.where(test_df['Close Price'].diff() >= 0, 1, 0)\n",
    "\n",
    "train_df['Tomorrow Movement'] = train_df['Tomorrow Movement'].shift(-1)\n",
    "test_df['Tomorrow Movement'] = test_df['Tomorrow Movement'].shift(-1)\n",
    "\n",
    "print(train_df.head())\n",
    "print(train_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !--- You can add your own data preprocessing here ---!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2263, 6)\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with NaN values\n",
    "\n",
    "train_df = train_df.dropna()\n",
    "test_df = test_df.dropna()\n",
    "\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2263, 5)\n",
      "   Open Price  Close Price  High Price  Low Price      Volume\n",
      "0      902.99       931.80      934.73     899.35  4048270080\n",
      "1      929.17       927.45      936.63     919.53  5413910016\n",
      "2      931.17       934.70      943.85     927.28  5392620032\n",
      "3      927.45       906.65      927.45     902.37  4704940032\n",
      "4      905.73       909.73      910.00     896.81  4991549952\n",
      "(2263,)\n",
      "0    0.0\n",
      "1    1.0\n",
      "2    0.0\n",
      "3    1.0\n",
      "4    0.0\n",
      "Name: Tomorrow Movement, dtype: float64\n",
      "-----\n",
      "(251, 5)\n",
      "   Open Price  Close Price  High Price  Low Price      Volume\n",
      "0     2683.73      2695.81     2695.89    2682.36  1846463232\n",
      "1     2697.85      2713.06     2714.37    2697.77  2090595328\n",
      "2     2719.31      2723.99     2729.29    2719.07  2100767744\n",
      "3     2731.33      2743.15     2743.45    2727.92  1918869120\n",
      "4     2742.67      2747.71     2748.51    2737.60  1894823936\n",
      "(251,)\n",
      "0    1.0\n",
      "1    1.0\n",
      "2    1.0\n",
      "3    1.0\n",
      "4    1.0\n",
      "Name: Tomorrow Movement, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Divide x and y data\n",
    "\n",
    "train_x_df = train_df.drop(columns=['Tomorrow Movement'])\n",
    "train_y_df = train_df['Tomorrow Movement']\n",
    "\n",
    "test_x_df = test_df.drop(columns=['Tomorrow Movement'])\n",
    "test_y_df = test_df['Tomorrow Movement']\n",
    "\n",
    "print(train_x_df.shape)\n",
    "print(train_x_df.head())\n",
    "print(train_y_df.shape)\n",
    "print(train_y_df.head())\n",
    "print('-----')\n",
    "print(test_x_df.shape)\n",
    "print(test_x_df.head())\n",
    "print(test_y_df.shape)\n",
    "print(test_y_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trent\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\trent\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\trent\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Open Price  Close Price  High Price  Low Price    Volume\n",
      "0   -1.552572    -1.494607   -1.505683  -1.541181  0.813175\n",
      "1   -1.498571    -1.503581   -1.501760  -1.499581  1.823826\n",
      "2   -1.494446    -1.488625   -1.486853  -1.483605  1.808070\n",
      "3   -1.502119    -1.546489   -1.520714  -1.534956  1.299148\n",
      "4   -1.546921    -1.540136   -1.556744  -1.546417  1.511255\n",
      "0    0.0\n",
      "1    1.0\n",
      "2    0.0\n",
      "3    1.0\n",
      "4    0.0\n",
      "Name: Tomorrow Movement, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Normalize data\n",
    "\n",
    "# !--- Modify here if you want ---!\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_x_df)\n",
    "\n",
    "normalized_train_x_df = scaler.transform(train_x_df)\n",
    "normalized_train_x_df = np.transpose(normalized_train_x_df)\n",
    "\n",
    "normalized_train_x_df = pd.DataFrame({\n",
    "    'Open Price': normalized_train_x_df[0],\n",
    "    'Close Price': normalized_train_x_df[1],\n",
    "    'High Price': normalized_train_x_df[2],\n",
    "    'Low Price': normalized_train_x_df[3],\n",
    "    'Volume': normalized_train_x_df[4],\n",
    "})\n",
    "\n",
    "normalized_test_x_df = scaler.transform(test_x_df)\n",
    "normalized_test_x_df = np.transpose(normalized_test_x_df)\n",
    "normalized_test_x_df = pd.DataFrame({\n",
    "    'Open Price': normalized_test_x_df[0],\n",
    "    'Close Price': normalized_test_x_df[1],\n",
    "    'High Price': normalized_test_x_df[2],\n",
    "    'Low Price': normalized_test_x_df[3],\n",
    "    'Volume': normalized_test_x_df[4],\n",
    "})\n",
    "\n",
    "print(normalized_train_x_df.head())\n",
    "print(train_y_df[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trent\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:\n",
      "0.5475033141847105\n",
      "\n",
      "testing accuracy:\n",
      "0.5258964143426295\n",
      "\n",
      "predicted testing labels:\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Train & Predict using Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "lr_model =  LogisticRegression()\n",
    "lr_model.fit(normalized_train_x_df, train_y_df)\n",
    "\n",
    "print('training accuracy:')\n",
    "lr_training_pred = lr_model.predict(normalized_train_x_df) # !-- Predict training target & print the training accuracy here --!\n",
    "lr_training_acc = np.mean(lr_training_pred == train_y_df)\n",
    "print(lr_training_acc)\n",
    "\n",
    "print('\\ntesting accuracy:')\n",
    "# !-- Predict testing target & print the testing accuracy here --!\n",
    "lr_predict_test_result = lr_model.predict(normalized_test_x_df)\n",
    "lr_testing_acc = np.mean(lr_predict_test_result == test_y_df)\n",
    "print(lr_testing_acc)\n",
    "\n",
    "print('\\npredicted testing labels:')\n",
    "print(lr_predict_test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision, recall, fbeta-score:\n",
      "(0.5137282196515144, 0.5258964143426295, 0.3694764768608263, None)\n",
      "\n",
      "confusion matrix(tn, fp, fn, tp):\n",
      "(1, 118, 1, 131)\n"
     ]
    }
   ],
   "source": [
    "# Print precision, recall, fbeta-score and confusion matrix\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print('precision, recall, fbeta-score:')\n",
    "print(precision_recall_fscore_support(test_y_df, lr_predict_test_result, average='weighted'))\n",
    "print('\\nconfusion matrix(tn, fp, fn, tp):')\n",
    "tn, fp, fn, tp = confusion_matrix(test_y_df, lr_predict_test_result).ravel()\n",
    "print((tn, fp, fn, tp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:\n",
      "0.5483870967741935\n",
      "\n",
      "testing accuracy:\n",
      "0.5258964143426295\n",
      "\n",
      "predicted testing labels:\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Train & Predict with SVC\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_model =  SVC(gamma='scale')\n",
    "svc_model.fit(normalized_train_x_df, train_y_df) # !-- Fill the training data here --!\n",
    "\n",
    "print('training accuracy:')\n",
    "lr_training_pred = svc_model.predict(normalized_train_x_df)\n",
    "svc_training_acc = np.mean(lr_training_pred == train_y_df)\n",
    "print(svc_training_acc)\n",
    "\n",
    "print('\\ntesting accuracy:')\n",
    "# !-- Predict testing target & print the testing accuracy here --!\n",
    "svc_predict_test_result = svc_model.predict(normalized_test_x_df)\n",
    "svc_testing_acc = np.mean(svc_predict_test_result == test_y_df)\n",
    "print(svc_testing_acc)\n",
    "\n",
    "print('\\npredicted testing labels:')\n",
    "print(svc_predict_test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision, recall, fbeta-score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trent\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.2765670386184346, 0.5258964143426295, 0.3624977895207681, None)\n",
      "\n",
      "confusion matrix(tn, fp, fn, tp):\n",
      "(0, 119, 0, 132)\n"
     ]
    }
   ],
   "source": [
    "# Print precision, recall, fbeta-score and confusion matrix\n",
    "\n",
    "print('precision, recall, fbeta-score:')\n",
    "print(precision_recall_fscore_support(test_y_df, svc_predict_test_result, average='weighted'))\n",
    "print('\\nconfusion matrix(tn, fp, fn, tp):')\n",
    "tn, fp, fn, tp = confusion_matrix(test_y_df, svc_predict_test_result).ravel()\n",
    "print((tn, fp, fn, tp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2263, 2)\n",
      "   0  1\n",
      "0  1  0\n",
      "1  0  1\n",
      "2  1  0\n",
      "3  0  1\n",
      "4  1  0\n"
     ]
    }
   ],
   "source": [
    "# Define NN output groundtruth\n",
    "\n",
    "falling_prob = pd.DataFrame(data=np.where(train_y_df == 0, 1, 0)[:])\n",
    "train_y_df = pd.DataFrame(data=np.where(train_y_df == 0, 0, 1)[:])\n",
    "train_y_df = pd.concat( [ falling_prob, train_y_df ], axis=1, ignore_index=True )\n",
    "\n",
    "falling_prob = pd.DataFrame(data=np.where(test_y_df == 0, 1, 0)[:])\n",
    "test_y_df = pd.DataFrame(data=np.where(test_y_df == 0, 0, 1)[:])\n",
    "test_y_df = pd.concat( [ falling_prob, test_y_df ], axis=1, ignore_index=True )\n",
    "\n",
    "print(train_y_df.shape)\n",
    "print(train_y_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 - loss:526.0357055664\n",
      "epoch:100 - loss:416.2016296387\n",
      "epoch:200 - loss:415.3622131348\n",
      "epoch:300 - loss:415.1055908203\n",
      "epoch:400 - loss:414.9973144531\n",
      "epoch:500 - loss:414.9463500977\n",
      "epoch:600 - loss:414.9208679199\n",
      "epoch:700 - loss:414.9069213867\n",
      "epoch:800 - loss:414.8977050781\n",
      "epoch:900 - loss:414.8901367188\n"
     ]
    }
   ],
   "source": [
    "# Define NN structure\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# !--- You can modify the NN structure here ---!\n",
    "class M_NN(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(M_NN, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H)\n",
    "        self.linear2 = torch.nn.Linear(H, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.linear1(x)\n",
    "        acti_out = F.relu(h)\n",
    "        y_pred = self.linear2(h)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "# N = batch size, D_in = input size, H = hidden size, D_out = output size\n",
    "N, D_in, H, D_out = 300, 5, 100, 2  # !--- You can modify here ---!\n",
    "\n",
    "model = M_NN(D_in, H, D_out)\n",
    "criterion = torch.nn.BCEWithLogitsLoss(reduction='sum') # !--- You can modify here ---!\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3) # !--- You can modify here ---!\n",
    "\n",
    "\n",
    "# Train NN\n",
    "# !--- You can modify here ---!\n",
    "\n",
    "for t in range(1000):\n",
    "    for batch_num in range(N, len(normalized_train_x_df), N): \n",
    "        X = torch.Tensor(normalized_train_x_df.to_numpy())[batch_num-N:batch_num]\n",
    "        Y = torch.Tensor(train_y_df.to_numpy())[batch_num-N:batch_num]\n",
    "        y_pred = model(X) # !-- Fill the training batch data here --!\n",
    "        loss = criterion(y_pred, Y) # !-- Fill the prediction & groundtruth here to calculate loss --!\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if (t%100 == 0):\n",
    "        print('epoch:%d - loss:%.10f' % (t, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:\n",
      "0.5497127706584181\n",
      "\n",
      "testing accuracy:\n",
      "0.5219123505976095\n",
      "\n",
      "predicted testing prob:\n",
      "tensor([[ 3.1489e-02, -3.1790e-02],\n",
      "        [ 4.6007e-02, -4.7118e-02],\n",
      "        [ 2.2245e-02, -2.4210e-02],\n",
      "        [ 4.2855e-02, -4.2700e-02],\n",
      "        [ 2.8167e-02, -2.7563e-02],\n",
      "        [ 1.4437e-02, -1.6183e-02],\n",
      "        [ 2.6864e-02, -2.5561e-02],\n",
      "        [ 5.4298e-02, -5.4996e-02],\n",
      "        [ 6.3450e-02, -6.4568e-02],\n",
      "        [-2.2035e-02,  2.1339e-02],\n",
      "        [ 7.6339e-02, -7.6734e-02],\n",
      "        [ 2.1561e-02, -2.1525e-02],\n",
      "        [ 5.7131e-02, -5.6638e-02],\n",
      "        [ 9.1495e-02, -9.2223e-02],\n",
      "        [ 4.8534e-02, -4.8801e-02],\n",
      "        [ 2.5732e-02, -2.4936e-02],\n",
      "        [ 2.7160e-02, -2.6068e-02],\n",
      "        [ 1.0494e-01, -1.0564e-01],\n",
      "        [ 6.5963e-03, -7.3728e-03],\n",
      "        [ 1.3529e-02, -1.4268e-02],\n",
      "        [ 2.5977e-02, -2.5552e-02],\n",
      "        [ 4.7432e-02, -5.0999e-02],\n",
      "        [-7.9345e-02,  7.9732e-02],\n",
      "        [-2.0523e-01,  2.0194e-01],\n",
      "        [ 2.3404e-01, -2.3243e-01],\n",
      "        [-2.3155e-02,  1.2504e-02],\n",
      "        [-2.4487e-01,  2.4515e-01],\n",
      "        [ 8.2429e-02, -7.0499e-02],\n",
      "        [ 5.0986e-02, -5.2752e-02],\n",
      "        [ 3.8607e-02, -3.8572e-02],\n",
      "        [ 1.2179e-01, -1.2364e-01],\n",
      "        [ 6.8363e-02, -6.3016e-02],\n",
      "        [ 1.7711e-02, -2.3934e-02],\n",
      "        [-8.2437e-03,  6.3116e-03],\n",
      "        [-5.0290e-02,  4.2415e-02],\n",
      "        [-1.4996e-02,  1.0450e-02],\n",
      "        [ 8.6763e-02, -8.7415e-02],\n",
      "        [ 7.6993e-02, -7.7262e-02],\n",
      "        [-6.9120e-02,  6.6506e-02],\n",
      "        [-7.9894e-02,  7.7608e-02],\n",
      "        [-7.4308e-02,  7.4475e-02],\n",
      "        [ 8.9293e-02, -8.8793e-02],\n",
      "        [ 1.0756e-01, -1.0948e-01],\n",
      "        [ 1.4485e-02, -1.0950e-02],\n",
      "        [ 5.3318e-02, -5.2926e-02],\n",
      "        [ 3.1407e-02, -2.9684e-02],\n",
      "        [ 1.0427e-01, -1.0508e-01],\n",
      "        [ 5.6510e-03, -6.8472e-03],\n",
      "        [-4.3250e-02,  4.2082e-02],\n",
      "        [-3.9869e-02,  4.0124e-02],\n",
      "        [-3.3482e-03,  2.0983e-03],\n",
      "        [ 4.3076e-02, -4.6410e-02],\n",
      "        [-4.8780e-02,  5.3439e-02],\n",
      "        [ 1.4036e-02, -1.5212e-02],\n",
      "        [-8.7953e-03,  2.2205e-03],\n",
      "        [-1.1234e-01,  1.1160e-01],\n",
      "        [-1.5223e-01,  1.4980e-01],\n",
      "        [ 1.0153e-01, -9.8959e-02],\n",
      "        [-1.3160e-01,  1.3395e-01],\n",
      "        [-2.4317e-02,  2.1099e-02],\n",
      "        [ 5.4043e-02, -5.8897e-02],\n",
      "        [-1.2454e-01,  1.3061e-01],\n",
      "        [ 4.7106e-02, -4.4865e-02],\n",
      "        [ 1.3960e-01, -1.3999e-01],\n",
      "        [ 9.2590e-03, -1.0280e-02],\n",
      "        [-1.0910e-01,  1.1079e-01],\n",
      "        [-4.1921e-02,  3.2081e-02],\n",
      "        [ 3.9053e-02, -4.1564e-02],\n",
      "        [-2.2229e-02,  1.7786e-02],\n",
      "        [ 1.5503e-02, -1.9101e-02],\n",
      "        [-5.2863e-02,  5.4725e-02],\n",
      "        [ 1.4630e-02, -1.6273e-02],\n",
      "        [ 3.4814e-02, -3.7265e-02],\n",
      "        [ 3.3101e-03, -4.4448e-03],\n",
      "        [-6.9757e-03,  9.1113e-03],\n",
      "        [-4.4257e-02,  4.6122e-02],\n",
      "        [-1.3608e-02,  1.4465e-02],\n",
      "        [-1.0513e-01,  1.0885e-01],\n",
      "        [ 1.3693e-02, -9.9455e-03],\n",
      "        [ 3.9174e-02, -4.1447e-02],\n",
      "        [-8.2606e-03,  1.0263e-02],\n",
      "        [-6.8144e-02,  6.5722e-02],\n",
      "        [ 3.2829e-02, -2.8777e-02],\n",
      "        [-4.7002e-02,  4.5902e-02],\n",
      "        [ 1.3273e-02, -6.9457e-03],\n",
      "        [ 9.2298e-02, -9.4038e-02],\n",
      "        [ 2.5691e-03, -4.7726e-03],\n",
      "        [ 1.0289e-02, -7.9758e-03],\n",
      "        [ 5.2424e-02, -5.3181e-02],\n",
      "        [ 4.7259e-02, -4.8741e-02],\n",
      "        [ 1.8336e-02, -1.8852e-02],\n",
      "        [-1.6574e-03,  1.0528e-04],\n",
      "        [-5.6183e-03,  7.8093e-03],\n",
      "        [ 2.7276e-02, -2.9224e-02],\n",
      "        [ 7.3893e-03, -8.8826e-03],\n",
      "        [-1.0094e-03,  1.0362e-03],\n",
      "        [ 2.3341e-02, -2.5541e-02],\n",
      "        [-2.2541e-02,  2.1822e-02],\n",
      "        [ 6.1099e-02, -6.0781e-02],\n",
      "        [ 1.1603e-02, -6.8586e-03],\n",
      "        [-9.3982e-05,  3.9355e-04],\n",
      "        [-2.5640e-02,  2.7231e-02],\n",
      "        [ 5.8271e-02, -6.0638e-02],\n",
      "        [-1.5822e-02,  1.6193e-02],\n",
      "        [ 4.7743e-02, -4.9137e-02],\n",
      "        [ 2.5616e-02, -2.6476e-02],\n",
      "        [ 1.7980e-02, -1.7088e-02],\n",
      "        [ 6.8582e-02, -6.8176e-02],\n",
      "        [ 1.2683e-02, -1.1788e-02],\n",
      "        [ 4.8902e-02, -4.9072e-02],\n",
      "        [ 1.9578e-02, -2.2306e-02],\n",
      "        [ 2.6823e-02, -2.6283e-02],\n",
      "        [-2.2319e-03,  1.0995e-03],\n",
      "        [ 2.3877e-02, -2.4384e-02],\n",
      "        [ 5.9858e-02, -5.7237e-02],\n",
      "        [ 4.1947e-02, -4.0583e-02],\n",
      "        [ 4.7967e-02, -4.6986e-02],\n",
      "        [ 1.5638e-02, -1.6603e-02],\n",
      "        [-2.6196e-02,  2.7335e-02],\n",
      "        [ 1.9246e-02, -2.0160e-02],\n",
      "        [-3.8563e-02,  4.3186e-02],\n",
      "        [ 1.4603e-02, -1.6096e-02],\n",
      "        [-6.7246e-02,  6.2163e-02],\n",
      "        [ 5.0373e-02, -5.1640e-02],\n",
      "        [-1.5074e-02,  1.0275e-02],\n",
      "        [ 5.9239e-02, -5.8630e-02],\n",
      "        [-5.7316e-02,  5.6869e-02],\n",
      "        [ 3.9422e-02, -3.8217e-02],\n",
      "        [ 5.9684e-02, -6.0664e-02],\n",
      "        [ 5.4203e-02, -5.5055e-02],\n",
      "        [ 3.1950e-02, -3.2311e-02],\n",
      "        [ 2.1181e-03, -3.3029e-03],\n",
      "        [ 5.8640e-02, -5.9207e-02],\n",
      "        [ 3.2781e-02, -3.2771e-02],\n",
      "        [ 1.5928e-02, -1.5598e-02],\n",
      "        [ 6.9855e-02, -7.1967e-02],\n",
      "        [ 4.0298e-02, -3.9691e-02],\n",
      "        [ 1.8914e-02, -1.8835e-02],\n",
      "        [ 1.9915e-02, -2.1302e-02],\n",
      "        [ 4.3750e-02, -4.3711e-02],\n",
      "        [ 3.2270e-02, -3.2878e-02],\n",
      "        [ 1.0557e-01, -1.0723e-01],\n",
      "        [ 4.2868e-02, -4.5656e-02],\n",
      "        [-1.8051e-02,  2.0311e-02],\n",
      "        [-1.0342e-02,  1.0448e-02],\n",
      "        [ 4.8522e-02, -5.1016e-02],\n",
      "        [ 1.4631e-02, -1.4350e-02],\n",
      "        [ 9.4025e-02, -9.4692e-02],\n",
      "        [ 5.7085e-02, -5.7141e-02],\n",
      "        [ 5.5088e-02, -5.5363e-02],\n",
      "        [ 3.7071e-02, -3.8924e-02],\n",
      "        [ 3.2234e-02, -3.2974e-02],\n",
      "        [ 2.0851e-02, -2.2267e-02],\n",
      "        [ 1.6187e-02, -1.5275e-02],\n",
      "        [-8.9067e-03,  6.9431e-03],\n",
      "        [ 5.5478e-02, -5.6659e-02],\n",
      "        [ 1.7143e-02, -1.3322e-02],\n",
      "        [ 4.9981e-02, -5.3354e-02],\n",
      "        [ 6.0416e-02, -6.1410e-02],\n",
      "        [ 3.8777e-02, -3.9109e-02],\n",
      "        [ 3.4465e-02, -3.7739e-02],\n",
      "        [ 3.2274e-02, -3.2951e-02],\n",
      "        [ 1.8427e-02, -2.0352e-02],\n",
      "        [ 6.0162e-02, -6.1201e-02],\n",
      "        [ 6.8527e-02, -6.9625e-02],\n",
      "        [ 2.9536e-02, -2.9469e-02],\n",
      "        [ 7.3040e-02, -7.3820e-02],\n",
      "        [ 2.2951e-02, -2.2705e-02],\n",
      "        [ 5.0255e-02, -5.0319e-02],\n",
      "        [ 4.6480e-02, -4.4740e-02],\n",
      "        [ 4.2372e-02, -4.0455e-02],\n",
      "        [ 1.8674e-02, -1.7131e-02],\n",
      "        [ 4.1567e-02, -4.4355e-02],\n",
      "        [ 2.2642e-02, -2.4227e-02],\n",
      "        [ 7.6509e-02, -7.7287e-02],\n",
      "        [ 4.5582e-02, -4.5230e-02],\n",
      "        [ 6.1959e-02, -6.3168e-02],\n",
      "        [ 4.2168e-02, -4.0660e-02],\n",
      "        [ 2.9563e-03, -2.7623e-03],\n",
      "        [ 7.1972e-02, -7.4526e-02],\n",
      "        [ 4.7546e-02, -4.8508e-02],\n",
      "        [ 7.7297e-02, -7.9150e-02],\n",
      "        [ 6.9966e-02, -7.1232e-02],\n",
      "        [ 4.7429e-02, -4.6647e-02],\n",
      "        [ 3.3801e-02, -3.4334e-02],\n",
      "        [ 1.5694e-02, -1.9318e-02],\n",
      "        [ 4.5054e-02, -4.8590e-02],\n",
      "        [ 5.7772e-02, -5.9498e-02],\n",
      "        [ 4.6174e-02, -4.7879e-02],\n",
      "        [ 4.7512e-02, -4.9022e-02],\n",
      "        [ 3.4010e-02, -3.5606e-02],\n",
      "        [ 1.2816e-02, -8.5692e-03],\n",
      "        [ 6.4315e-03, -4.4122e-03],\n",
      "        [ 6.2413e-02, -6.0307e-02],\n",
      "        [ 3.5443e-02, -3.7730e-02],\n",
      "        [-1.7394e-01,  1.7426e-01],\n",
      "        [-8.4218e-02,  8.3612e-02],\n",
      "        [ 3.5903e-02, -2.7860e-02],\n",
      "        [-2.1054e-02,  1.7816e-02],\n",
      "        [ 1.2699e-01, -1.2931e-01],\n",
      "        [ 3.2111e-02, -2.6728e-02],\n",
      "        [-5.0940e-02,  5.3216e-02],\n",
      "        [-8.0745e-04, -3.7988e-03],\n",
      "        [-2.3732e-02,  2.3808e-02],\n",
      "        [ 7.8911e-02, -7.5621e-02],\n",
      "        [-1.8113e-01,  1.8101e-01],\n",
      "        [ 8.7338e-02, -9.1470e-02],\n",
      "        [-2.3930e-03,  3.1181e-03],\n",
      "        [-8.6823e-02,  8.9884e-02],\n",
      "        [ 1.2516e-01, -1.2608e-01],\n",
      "        [ 3.1667e-02, -3.9402e-02],\n",
      "        [ 8.3063e-02, -8.2150e-02],\n",
      "        [-2.4933e-02,  2.7466e-02],\n",
      "        [ 4.4220e-02, -4.4341e-02],\n",
      "        [ 5.6134e-02, -5.6951e-02],\n",
      "        [ 1.2611e-01, -1.2781e-01],\n",
      "        [ 3.2384e-02, -3.2046e-02],\n",
      "        [ 7.0267e-03, -2.9875e-03],\n",
      "        [-9.6304e-02,  9.6759e-02],\n",
      "        [-1.0784e-02,  5.4208e-03],\n",
      "        [-6.8208e-02,  6.9709e-02],\n",
      "        [ 1.1569e-01, -1.1241e-01],\n",
      "        [ 6.2947e-02, -6.5091e-02],\n",
      "        [-8.1118e-02,  8.2842e-02],\n",
      "        [-2.3806e-02,  2.1968e-02],\n",
      "        [-3.0013e-02,  2.6092e-02],\n",
      "        [-3.6903e-02,  3.3167e-02],\n",
      "        [ 5.7456e-02, -5.8642e-02],\n",
      "        [ 4.9871e-02, -4.8697e-02],\n",
      "        [ 1.4542e-01, -1.4521e-01],\n",
      "        [ 1.3602e-02, -1.4775e-02],\n",
      "        [ 8.9665e-02, -8.9626e-02],\n",
      "        [ 3.8557e-02, -3.7304e-02],\n",
      "        [-1.7598e-01,  1.7586e-01],\n",
      "        [-1.7507e-01,  1.7494e-01],\n",
      "        [ 1.2066e-01, -1.1090e-01],\n",
      "        [-1.4304e-01,  1.4086e-01],\n",
      "        [ 3.3319e-02, -2.4020e-02],\n",
      "        [-6.6654e-02,  6.7785e-02],\n",
      "        [-2.8169e-02,  2.0386e-02],\n",
      "        [-1.8458e-02,  1.8395e-02],\n",
      "        [-7.6895e-02,  7.6784e-02],\n",
      "        [-1.1753e-01,  1.1858e-01],\n",
      "        [-4.5359e-02,  4.5682e-02],\n",
      "        [-1.1764e-01,  1.1147e-01],\n",
      "        [-7.8706e-02,  8.1693e-02],\n",
      "        [-1.3456e-01,  1.2536e-01],\n",
      "        [-1.9639e-01,  1.9384e-01],\n",
      "        [ 2.1845e-01, -2.1676e-01],\n",
      "        [ 9.5992e-02, -8.5632e-02],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        [-7.3027e-02,  7.0189e-02]], grad_fn=<AddmmBackward>)\n",
      "\n",
      "predicted testing labels:\n",
      "[1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1 1 1 1 1 0 0 0 1\n",
      " 1 0 0 0 1 1 1 1 1 1 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 0 0 1 0 1 0 1 1 1\n",
      " 0 0 0 0 1 1 0 0 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 0 0 1 0 1 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 0 1 0 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1\n",
      " 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 0 1 1 1 1 1 0 0 0 1\n",
      " 1 0 0 0 0 1 1 1 1 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "\n",
    "nn_predict_train_y = model(torch.Tensor(normalized_train_x_df.to_numpy()))\n",
    "result_train = np.where(nn_predict_train_y[:, 0] > nn_predict_train_y[:, 1], 1, 0) # !-- You can modify here --!\n",
    "print('training accuracy:')\n",
    "print(accuracy_score(train_y_df[0], result_train))\n",
    "\n",
    "nn_predict_test_y = model(torch.Tensor(normalized_test_x_df.to_numpy()))\n",
    "result_test = np.where(nn_predict_test_y[:, 0] > nn_predict_test_y[:, 1], 1, 0) # !-- You can modify here --!\n",
    "print('\\ntesting accuracy:')\n",
    "print(accuracy_score(test_y_df[0], result_test))\n",
    "\n",
    "print('\\npredicted testing prob:')\n",
    "print(nn_predict_test_y)\n",
    "print('\\npredicted testing labels:')\n",
    "print(result_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "precision, recall, fbeta-score:\n",
      "(0.5390833287570039, 0.5219123505976095, 0.5046506732366034, None)\n",
      "\n",
      "confusion matrix(tn, fp, fn, tp):\n",
      "(45, 87, 33, 86)\n"
     ]
    }
   ],
   "source": [
    "# Print precision, recall, fbeta-score and confusion matrix\n",
    "\n",
    "print('\\nprecision, recall, fbeta-score:')\n",
    "print(precision_recall_fscore_support(test_y_df[0], result_test, average='weighted'))\n",
    "print('\\nconfusion matrix(tn, fp, fn, tp):')\n",
    "tn, fp, fn, tp = confusion_matrix(test_y_df[0], result_test).ravel()\n",
    "print((tn, fp, fn, tp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
